# Formatted with Black
# https://black.now.sh/?version=stable&state=_Td6WFoAAATm1rRGAgAhARYAAAB0L-Wj4DNiDm9dAD2IimZxl1N_Wk6rkmrIVYGF2f6jjaZ38Qw5Sa1-cFtDHwlTZRfJYYk61vi1w6kBDUj-SgU4hp8J9Xc49E4Jkolu5Gn2tBCA1VpePUjd2py3tgSdFpmuRjoMMZozya7BAT5X6_UJ__zruP8gmCI7_j-uNTbQDyrAHGIBumc2fbpsC6WAxnVrJsGsKbQy8LnyUOvZrVb67syL-tSmjTLEiaCobw9AG54F_FUEiaxykYOk9nYIUnJ_a9n3EDUfXCR7Pk5lM72Xz8VyFZ2rjI2spWcFlmtZ6yLbCI2VnQYh9HovF4yBZuGGkCW8xblh6Ry4I5Vqh9rl8n8xdGFud73gFz_EehWqo7RP1VnmNQoi2FtP7Q8mV5SzCLJRKr5vOFyq3ysw9ADSVbMIFfWvXMrHnPDaNl10weMZWlbatEbY0qnkVM3iuBmxVYGlFv5moA32rFfmJLYPFnjTmyy6RYrB6N6ERE5itb9V4_cKQ5qTR-RRX1ACA1LQv-lWbf7M0np06NJzsvvYd-6-svsyITp7rCmDYoWIDF94CBLhxwpqHq5SlsdnrhyDXFM2eNeRV4QP_YISNNitO3oReqYUo0dE8byaH8e7DTjGFUaaK6eMgw-WMEA9kRmxkKH_OxtEb1W4888snG04MvHSCm9KS7V10mlI7wIquqWsAsfgGm1HVVgINyrqQ-GLvC2hfSt_FwD-ET0Y2gm2f6519Zzl60yi3RfXj5U0XNmIdxQqVqvitffHr8rHH7V7ZY6G08VN2Y3w4NYILYrC89x182JCbPD68B88PTLrLeXZ20VGJDcvFkNfkufZ6_6UAJ9PBQLi0YeX0Z0Y1zUKNc-KC7bz88L58196kJycOJp9eidTEVKl0PUW7GPWXUXobzEdQkpkBY4GFLlsyx246m5nTdEawGAPnxul5iSUpM5rHMqyTgz1ZbktKbsvr0yCRBC7iiH0KaOJesrJozo8M1PLCg8N73P24z2ZwCpaYsfj2pcT3tKE1z4O0avk04DbMdR8BIFp-5kq-twcAWV9XivZd1RRSrHekJR1B8dGmgquBcTXPONOgbAbqgcGEJqWxcgmVJPsEx3qh239DGaes-VDCCD1w2a9Xskl1qji8ISHLtTHVWbZ2zjYTAAFYS3GNu-r84jWqpn3urT8S3HDICsSp255am7vNL5WK6KLLmkIysq3hm7esgwO3CeszVuX5PsGamx5Rd0NC13IIuYWprC-Bvjc8atpDybf6gCAW8ep_4W1EjsbfIVFEGAz3_j3hd1EsUtNjyUeII-OjKd3mAt_2A6d1_KQnq9ZoGLiP8wV9enXvUauu4EVYAgHFpe8AW9Yjruiy8MEjXMleILQHiD9p7Gh9Yo90DeYMZ9QlePyfzmjAf7-p45-fxG9cpujGrbGXC42nMG3CK8ChFE_qi7okAtQlG8b870UfiJpRTSkR6e5QwHgLiJkOdMrN82OR-QMDqdTfNf9zyK7iRfE30IqlP_xK-LhVGAvAe6QHXPd1T1kfeOTz7DduVkHvT01V-IVlydJZIM-2RRNX168cMS4x2fDJJPqntmvykR2YUQiDnqHf5wu_b1Tc6Fl2xE_Yy_Varh-P3uYRF6uOxYAydW59-AHWqHO5CyjB34IMKQaV2m70hV4Ap88RInXFnL9qf5vm8DlMRjbEJYegsM2aNgdBUXd53mI7RA0E9nl42q1eUjwVoYZczj5R0gwoCpye9SYTpbNFsBfDTiNqjYJhO1HHskvkJI8NpAWoDmzk-hclZtSLi_itJWU2CdSiws-fZN3IVToIEuce3k6n1pYtkxxeIbhivfKxL2YRiqINXP7By2vhyvnYPGLtSpVd3SEYE1sUnwkX4RMtxBN_1CDdhVhmwt_EdxrR4KCLNzZ1jArQsBa63djYlwk8EXhkLPDwoBqKGiG5saskMPhNHu849otxS3Jak1EXkE2o170zJ68ThweoKABFtNun19sFniSn4mXUWX0KlXPLpJtVY9ku_4e40hHwXuF4RBApYxFHQYRqvZN3pO2l52Xm9rJq2KKw7hsjp_PbIle5_RTwqVqWDCLEF8LCo3b5FDVD9qZ7EiyN7dqU59x2nB2c36VtT1GS4dTkUXomHNoY8zGW_8NzEXbOOgzq4XHlbnv29mElhqETxRe3WPUGmpH8JlWrPdsgfpolU2U78PnVFOLXX6ic_tviWLE0TJ0nqGRXhyqwAu4yFlBsrdnN2tHkaOxauVZAsDgbewxPevp5_utmzzAuL-ZeC88kbRfEeMqEe-bZ48hcpdJEu7kDv4KYA2wXel-cZtXrkSIp3TuAzXmc2no93Lhyp6SaBMN7bV_XLttOT9omuNaALvsfGhuNVbgbiROeIPUSdh5F6VvuR3U-jD8zyIBVeM7iSlmoGcHMwYXsJ7HCwp-oGuqmQ0b4OSHbU8n9qwg3vnclS_lFQ3mr9XpI1S-XsxdZCQ0OQfpkcF6qA4U-93NBAKFXGl_vw42d9z7HSsw_Yuh3uBa19eolKfMu0iDVJTND0DnN5q64vzNQBm0bAzxTOBTzBRIZNu41fbcbd6NzwkY_Pqk5F2gl8YtMbEArqyqWUAB5FxlvmE3D4WeEwVLv47fa-CIzhtQ0fYm8aUmlfFtpilKybn77kOKTcg_8sLacrkVkhJRidFkOzDULyv4yhfiE3Y7wW4CumcEdV4DRrJ_mJVCl3igI_Plz4TgmZDPrNr-bBUgX57foT4tgjvYQRs1KQj83TF8yVE18ZrvM8uymAT-oEbdHilJT2xROkhOGrZon8J7bXZmjjz7URdU4KEpYdM54OBbB54ZmZS7KvVqLXXt9o5QgMRVdoPs3Jx_0jpkMUnjKTavQ0VhcbBmW9Thht703ALJ5ujtNmTw7otmqpxxUUy8YR1tOlR_1VPVfozsEpONpGTWWxTtV2VajDnLsqa2C9fjY8-pFQtFMyvaDYJD6KDEhiIRsPIoCVj5rIUf_AwOS7ZC03A_WImawiTvUIMFq9lpYAowCBj6zENLf4-1Jq1IR9S0_27YsZPkiNMiGe8DuEyrTQozwe1iXmYlT9UekkbRfFqNmsOc2xp2m1FiLVSSn7pR-I9B0Y7oR1kGj8zk__C-_1Qu67njAajgzStv-sXcUoDm2X9jG7a46Frl4kLE02wlb5ubF-wAjVBMyCErkDhbfOCquNTu1vlVyWIN_vq_SiRS6QZ1ru_SzDYKSZBE0ZhHABh_6isF3jTpRmJBEIIoeSzLN-eIjxKQmjuEHtM9nL0PY_EpLk4kiP-gumVzVaozmbLf3ioUDfs4ZPU40pL0K8TosEV9V7b--js2qAYi8h6uKbt-sSv_eDxeSl9wkgUEfA3OIe--s7fg1uGDZQPEXLi3zntX64_WSI71YOxsrGY7kDNBGxabnhBom_R5oWOUenOYGZoxOtoDIA5D3sZlqzIF3Hs82mU7dKpXF0objEYHMPSpjtTsy1lup1YdqnQw5CzGUFSrfWagtl6wNcXvVG6cq-SYtH3Lza5yTkMQJLVJE-w42QW8gj8G5EZwCxsL2KelGoMaDA2muF7jJTQ_e0dyy7plax_ycNBVz93zzqJK1mxWJEdceUGixi2j_9lB9bYSESvoXWvC40g5mN2wNTkkoFc-kDVg-GMjcrD2fZD1IlDW-6_Pp_d16I4isvtxCNT6QAMc6xB0pqBDCL3lw2-JMglGxqGqeb1Bs7UD0fp1RYYXJWX7cYyNnHdBt8IMrhQIZKcbFDo6z4fwcV5jmvxBuK7pVHccydwN2saEyAZUj8hwfDywRbhUu80qNXO9R-FEJZ7A-ZgUQXZhEpvzzphse10CoxBtDUyQZfA33-qOpXpdKof-2ru4zIHcmmBDXrY3ldMMVbQMq2z2xAdUnY6OaxmUXqE6wHXCjtFMiFuTGHcUy3HZmwncc4VH8jutGsSRYZRhg4uFzV9n4PefDa5SPiVMmr2Lt9GekAmqJbCymvHyGCGSPZB_rM-KYPlrccgMmOuT3KzUgmmV60Oi89v--xXeU8XlX2BHCPR58hK47rrVo_rmObs9aY1g3Hd_6jeOSJPecw-QWov1zp899Qz_r2rI1Fzqqv5pFuLulaTViXNRvf55K-ptBqi3uWneXO53ofxN5jGg5uPW479FN7PPJh3JbwOO-_jTr70OJ2omaAZXwmDWgpdyg482LfraViF07mcIuqZk7vxB6iB-oKBpXtL3jM5W9nzWmSUnvrECdf4Nk5g62wMBvawllVwZfnvSlc6x_xWwSgPkXUzk3GX_jXsYwOn1ip3BGHHjjrBM5QaKkClPam3nUIirsXEqv34SJmRNt3jPOsWXxo7wP0nTJanJcEFU4pUpUtOH5QG9uH9QzESJjoEviYa-_4Dgb7dVLrQpfBnD7Y0KBwf_1j4n7-8WBHhpe_dI1WlFtpwJLKCwh696nGKgoSvBDIVp8PbCKH6zXrQUbYFuv9s35Wh5D57TX99IMrBPto_UiLfB9VFnCWaLR-VihJ_9mYs9AT0tHttD1VNOCPtcV8DN6x2iB6eWdBxXCqQLd57U-ldiTftNFs2ymwyQajaTaE6QbpQsoFXGkS7EG--GgQKhoT57WQ2gRvrp6Iao4XJcDPrD5LePdv1EVGROWTsLjs3UEcaEwa_KXbT3W6i2xuSbcPXMw1djPgYiM1yJOSYckcMvl_xTzqYXsRlKAFHIXUUkGkm8tUeY1BRJaOGIjLTol8iINZhuF-qvA_u8wGEl2SXSXrjn3zStC9jfK46e1u_91gwYwfuF0xNZBOOQ-3ArPFuw8qOVNE7wd9bpBXKRLB84kM7Ba_qdh8C7XWBa_AxU8qFm6sKwZn5_tRcxERfH76eMi1wOsQSAQsVY6QO8g2jiF7FSGvVxscFsvh118Ctc6wAFUrSqZPm-ZLEPiCc_bdTVs1sDg99Dsl8QDTZu6KQvHLdKcKHUy-vxAADy7UUhebDspAABix3jZgAAsTrCp7HEZ_sCAAAAAARZWg==

from lxml import etree, html
from lxml.html.clean import clean_html
import pandas as pd
from datetime import date, datetime
import requests
import re
import os
import shutil
from ASECORP_BBDD import tagea_BBDD_ASECORP, devuelve_patrones
from selenium import webdriver

from io import StringIO
from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter
from pdfminer.converter import TextConverter
from pdfminer.layout import LAParams
from pdfminer.pdfpage import PDFPage

## Crea función que convierte lista a string en todas las columnas de DOCM_sumarios
## para evitar en presentación final los caracteres [' '] propios de las listas
def list2Str(lst):
    if type(lst) is list:  # apply conversion to list columns
        return ", ".join(lst)
    else:
        return lst


def pdf2txt(fname, pages=None):
    if not pages:
        pagenums = set()
    else:
        pagenums = set(pages)

    output = StringIO()
    manager = PDFResourceManager()
    converter = TextConverter(manager, output, laparams=LAParams())
    interpreter = PDFPageInterpreter(manager, converter)

    infile = open(fname, "rb")
    for page in PDFPage.get_pages(infile, pagenums):
        interpreter.process_page(page)
    infile.close()
    converter.close()
    text = output.getvalue()
    output.close
    return text


# # Mueve todos los fichero del directorio de trabajo a otro de archivo

source_dir = "./DOCMs"
target_dir = "./DOCMs_Anteriores"

file_names = os.listdir(source_dir)

for file_name in file_names:
    # shutil.move(os.path.join(source_dir, file_name), target_dir)
    # Evita que de error si el fichero que se mueve ya existe en dir destino
    try:
        os.remove(os.path.join(target_dir, file_name))
        shutil.move(os.path.join(source_dir, file_name), target_dir)
    except OSError:
        shutil.move(os.path.join(source_dir, file_name), target_dir)

# # Recoge resumen diario del DOCM de hoy


today = date.today()

# dd/mm/YYYY
hoy = today.strftime("%Y%m%d")
print("Fecha de Hoy =", today.strftime("%d/%m/%Y"))

URL_HTML_resumen = "https://docm.jccm.es/portaldocm/cambiarBoletin.do?fecha=" + str(hoy)


# URL_HTML_resumen

print("Accediendo a página del boletín")

# carga página HTML y genera árbol

response = requests.get(URL_HTML_resumen)
sumario_HTML = html.fromstring(response.text)

## Recoge Nombre Secciones Sumario

secciones = sumario_HTML.xpath('//*[@class="cabeceraCategoria"]/text()')
secciones = [re.sub("\r|\n|\t", "", seccion) for seccion in secciones]


def save_html(html, path):
    with open(path, "wb") as f:
        f.write(html)


save_html(response.content, "./DOCMs/Resumen-DOCM-" + hoy + ".html")

for seccion in sumario_HTML.xpath('//*[@class="cabeceraCategoria"]'):
    nombre_seccion = seccion.xpath("./text()")
    nombre_seccion = str(nombre_seccion[0]).strip()
    # print(nombre_seccion)

print("Accediendo a página resumen de disposiciones")

DOCM_sumarios = pd.DataFrame(columns=["item_Title", "item_urlHTML", "item_urlPDF"])

# lista = []
# for sumario in sumario_HTML.xpath('//*[@class="sumario"]'):
#    lista.append(sumario.text_content().strip())
#
# DOCM_sumarios['item_Title'] = lista
#
# lista = []
# for link_HTML in sumario_HTML.xpath('//*[@title="Ver los datos detallados del documento"]'):
#    link = link_HTML.xpath('./@href')
#    #print(link)
#    lista.append('https://docm.jccm.es/portaldocm' + str(link)[3:-2])
#
# DOCM_sumarios['item_urlHTML'] = lista
#
# lista = []
# for link_PDF in sumario_HTML.xpath('//div/a[@class="new-window"]'):
#    link = link_PDF.xpath('./@href')
#    #print(link)
#    lista.append('https://docm.jccm.es/portaldocm' + str(link)[3:-2])
#
# DOCM_sumarios['item_urlPDF'] = lista

# Compone la primera tabla con campos acceso a detalle disposiciones individuales

for sumario in sumario_HTML.xpath('//*[@class="sumario"]'):
    title = sumario.text_content().strip()
    # print(sumario)
    categoria = sumario.xpath("./preceding::h3[1]/text()")
    # print(categoria)
    link_HTML = sumario.xpath(
        'following-sibling::div[1]/a[@title="Ver los datos detallados del documento"]/@href'
    )
    link_HTML = "https://docm.jccm.es/portaldocm" + str(link_HTML)[3:-2]
    # print(link_HTML)
    link_PDF = sumario.xpath("./a/@href")
    link_PDF = "https://docm.jccm.es/portaldocm" + str(link_PDF)[3:-2]
    # print(link_PDF)

    DOCM_sumarios = DOCM_sumarios.append(
        {
            "seccion": categoria,
            "item_Title": title,
            "item_urlHTML": link_HTML,
            "item_urlPDF": link_PDF,
        },
        ignore_index=True,
    )

# Convierte columna seccion a string
DOCM_sumarios["seccion"] = DOCM_sumarios["seccion"].astype(str)

# Elimina caracteres \n \t y \r
DOCM_sumarios.replace(
    to_replace=[r"\\t|\\n|\\r", "\t|\n|\r"], value=["", ""], regex=True, inplace=True
)

# Elimina disposiciones con seccion que contenga las palabras AUTORIDADES y/o PERSONAL
terminos = ["AUTORIDADES Y PERSONAL", "AUTORIDADES", "PERSONAL"]
DOCM_sumarios = DOCM_sumarios.drop(
    DOCM_sumarios.index[
        DOCM_sumarios["seccion"].str.contains("|".join(terminos), na=False)
    ]
)

# Elimina disposiciones con item_Title que contenga las palabras Sanciones
terminos = ["Sanciones"]
DOCM_sumarios = DOCM_sumarios.drop(
    DOCM_sumarios.index[
        DOCM_sumarios["item_Title"].str.contains("|".join(terminos), na=False)
    ]
)

#### Necesita libreria Selenium para renderizar JS script
#
# options = webdriver.ChromeOptions()
# options.headless = True
# driver = webdriver.Chrome(options=options)
#
# driver.get(DOCM_sumarios['item_urlHTML'][0])
##print(driver.page_source)
# response = driver.page_source
#
# sumario_HTML = html.fromstring(response)
# numero_diario = sumario_HTML.xpath('//table[@class="tablaDetalle"]/tbody/tr[1]/td[2]/text()')
# numero_pagina = sumario_HTML.xpath('//table[@class="tablaDetalle"]/tbody/tr[3]/td[4]/text()')
# NID = sumario_HTML.xpath('//table[@class="tablaDetalle"]/tbody/tr[2]/td[2]/text()')
# rango = sumario_HTML.xpath('//table[@class="tablaDetalle"]/tbody/tr[5]/td[2]/text()')
# organo_emisor = sumario_HTML.xpath('//table[@class="tablaDetalle"]/tbody/tr[7]/td[2]/text()')

# print(numero_diario[0].strip(), numero_pagina[0].strip(), NID[0].strip(), rango[0].strip(), organo_emisor[0].strip())
# print()

# driver.quit()

print("Accediendo a página detalle de disposiciones")

### Recoge información de página de detalle con Selenium
### es necesario ya que la página se genera con un JS y
### hay que renderizarla con un headless web browser

options = webdriver.ChromeOptions()
options.headless = True
driver = webdriver.Chrome(options=options)

DOCM_sumarios["NID"] = ""
DOCM_sumarios["numero_diario"] = ""
DOCM_sumarios["numero_pagina"] = ""
DOCM_sumarios["rango"] = ""
DOCM_sumarios["organo_emisor"] = ""
DOCM_sumarios["Fecha_publicacion"] = ""

for i, row in DOCM_sumarios.iterrows():
    # carga página HTML y genera árbol
    driver.get(row["item_urlHTML"])
    # print(driver.page_source)
    response = driver.page_source

    sumario_HTML = html.fromstring(response)
    numero_diario = sumario_HTML.xpath(
        '//table[@class="tablaDetalle"]/tbody/tr[1]/td[2]/text()'
    )
    numero_pagina = sumario_HTML.xpath(
        '//table[@class="tablaDetalle"]/tbody/tr[3]/td[4]/text()'
    )
    NID = sumario_HTML.xpath('//table[@class="tablaDetalle"]/tbody/tr[2]/td[2]/text()')
    rango = sumario_HTML.xpath(
        '//table[@class="tablaDetalle"]/tbody/tr[5]/td[2]/text()'
    )
    organo_emisor = sumario_HTML.xpath(
        '//table[@class="tablaDetalle"]/tbody/tr[7]/td[2]/text()'
    )
    item_itle = sumario_HTML.xpath(
        '//table[@class="tablaDetalle"]/tbody/tr[9]/td[2]/text()'
    )

    # print(numero_diario[0].strip(), numero_pagina[0].strip(), NID[0].strip(), rango[0].strip(), organo_emisor[0].strip())

    DOCM_sumarios["NID"][i] = NID[0].strip()
    DOCM_sumarios["numero_diario"][i] = numero_diario[0].strip()
    DOCM_sumarios["numero_pagina"][i] = numero_pagina[0].strip()
    DOCM_sumarios["rango"][i] = rango[0].strip()
    DOCM_sumarios["organo_emisor"][i] = organo_emisor[0].strip()

    DOCM_sumarios["Fecha_publicacion"][i] = datetime.strptime(
        str(today), "%Y-%m-%d"
    ).date()

driver.quit()

# # Salva PDFs y Genera DF con datos Análisis de cada PDF

print("Generando Tags de patrones encontrados en disposiciones")

# Crea nueva columna vacía de tipo lista en tabla_analisis
# DOCM_sumarios['Referencias_completas'] = [[] for i in range(len(tabla_analisis))]
DOCM_sumarios["Tags"] = [[] for i in range(len(DOCM_sumarios))]
DOCM_sumarios["Match_ASECORP_BBDD"] = [[] for i in range(len(DOCM_sumarios))]

# Define expresiones REGEX para búsqueda de leyes, decretos, etc. referenciadas anteriormente
# pattern = ['Ley [0-9]+\/[0-9]+','Ley Orgánica [0-9]+\/[0-9]+','Decreto [0-9]+\/[0-9]+','Real Decreto [0-9]+\/[0-9]+','Real Decreto Legislativo [0-9]+\/[0-9]+','Real Decreto-ley [0-9]+\/[0-9]+','Orden [A-Z]+\/[0-9]+\/[0-9]+','Orden Circular [0-9]+\/[0-9]+','Reglamento \(UE\) [0-9]+\/[0-9]+', 'Reglamento de Ejeución \(UE\) [0-9]+\/[0-9]+' ,'Sentencia de [0-9]+ de [a-z]+ de [0-9]+','Sentencia [0-9]+\/[0-9]+','Orden de [0-9]+ de [a-z]+ de [0-9]+', 'Resolución de [0-9]+ de [a-z]+ de [0-9]+','Resolución [a-z]+\/[0-9]+\/[0-9]+', 'Nota de Servicio [0-9]+\/[0-9]+', 'Acuerdo multilateral M\-[0-9]+', 'Acuerdo Multilateral RID [0-9]+\/[0-9]+', 'Circular [0-9]+\/[0-9]+', 'Decisión \(UE\) [0-9]+\/[0-9]+', 'Decisión de Ejecución \(UE\) [0-9]+\/[0-9]+', 'Instrucción IS\-[0-9]+']
pattern = devuelve_patrones()

for i, row in DOCM_sumarios.iterrows():
    r = requests.get(row["item_urlPDF"])

    # Salva PDFs de enlaces a items
    filename = row["NID"].replace("/", "-")
    f = "./DOCMs/" + "DOCM_NID_" + filename + ".pdf"
    save_html(r.content, f)

    # Extrae texto de PDFs
    pdf_contents = pdf2txt(f)
    # print(pdf_contents)

    # Busca expresiones REGX coincidentes con Patrones definidos
    DOCM_sumarios["Tags"][i] = re.findall(
        "|".join(pattern), str(pdf_contents), flags=re.IGNORECASE
    )
    # print(DOCM_sumarios['Tags'][i])


# Elimina Tags duplicados
for i, row in DOCM_sumarios.iterrows():
    DOCM_sumarios["Tags"][i] = list(set(DOCM_sumarios["Tags"][i]))
    # print(DOCM_sumarios['Tags'][i])

# Aplica expresiones REGEX para búsqueda de leyes, decretos, etc. referenciadas anteriormente
regex_result = []
[regex_result.append(tag) for tags in DOCM_sumarios["Tags"] for tag in tags]

## Elimina duplicados
boletin_flat_list = list(set(regex_result))

print("Generando Tags de patrones encontrados en BBDD ASECORP")

# ## Importa BBDD ASECORP

# Inicializa datos de BBDD_ASECORP
boletin_ASECORP_flat_list = []
ASECORP_BBDD = pd.DataFrame()
ambitos = []

# Incluir en llamada a función el ambito territorial como lista
# si no se especifica ámbito los incluye todos
boletin_ASECORP_flat_list, ASECORP_BBDD, ambitos = tagea_BBDD_ASECORP(
    ["España", "Europa", "Castilla la Mancha"]
)

# print(ambitos)

## Busca coincidencias entre lista boletines BOEs explorados y lista boletines de BBDD ASECORP
set(boletin_flat_list) & set(boletin_ASECORP_flat_list)

# DOCM_sumarios['Tags'].isin(ASECORP_BBDD_BOE['Tags'])
# for row_to_compare in DOCM_sumarios['Tags']:
#    for row_comparing in ASECORP_BBDD['Tags']:
#        if set(row_comparing) & set(row_to_compare):
#            print(set(row_comparing) & set(row_to_compare))

print("Realizando Matching entre Tags encontrados en disposiciones y en BBDD ASECORP")

for i, row_to_compare in DOCM_sumarios.iterrows():
    for j, row_comparing in ASECORP_BBDD.iterrows():
        if set(row_to_compare["Tags"]) & set(row_comparing["Tags"]):
            DOCM_sumarios["Match_ASECORP_BBDD"][i].append(ASECORP_BBDD["Codigo"][j])
            # print(str(set(row_to_compare['Tags']) & set(row_comparing['Tags'])) + ' ' + str(row_comparing['Codigo']))


# # Genera Fichero EXCEL de resultados

DOCM_sumarios_final = DOCM_sumarios

## Cambia orden de columnas y elimina las no necesarias
DOCM_sumarios_final.rename(
    columns={"NID": "Item_id", "item_Title": "Item_Title", "item_urlPDF": "PDF_Link"},
    inplace=True,
)
DOCM_sumarios_final = DOCM_sumarios[
    [
        "Item_id",
        "Item_Title",
        "PDF_Link",
        "Fecha_publicacion",
        "Tags",
        "Match_ASECORP_BBDD",
    ]
]

## Aplica función de conversión de listas a strings
DOCM_sumarios_final = DOCM_sumarios_final.apply(lambda x: [list2Str(i) for i in x])

## Generar hyperlink a artículo BOE en CSV "=HYPERLINK("https://www.boe.es/boe/dias/2021/02/02/pdfs/BOE-A-2021-1474.pdf";"BOE-A-2021-1474")"
## https://www.boe.es/diario_boe/xml.php?id=## https://www.boe.es/boe/dias/2021/02/02/pdfs/BOE-A-2021-1474.pdf

DOCM_sumarios_final_CSV = DOCM_sumarios_final

DOCM_sumarios_final_CSV["Item_id"] = (
    "=HIPERVINCULO("
    + '"'
    + DOCM_sumarios_final_CSV["PDF_Link"]
    + '";'
    + '"'
    + DOCM_sumarios_final_CSV["Item_id"]
    + '")'
)

# Elimina columna PDF_Link
DOCM_sumarios_final_CSV = DOCM_sumarios_final_CSV[
    ["Item_id", "Item_Title", "Fecha_publicacion", "Tags", "Match_ASECORP_BBDD"]
]

print("Guardando resultados en fichero")

DOCM_sumarios_final_CSV.to_csv(
    "./ASECORP/Resultados_Matching_DOCM_" + today.strftime("%Y%m%d") + ".csv",
    index=False,
)
